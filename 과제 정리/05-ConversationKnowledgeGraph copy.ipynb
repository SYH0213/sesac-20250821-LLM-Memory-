{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationKGMemory\n",
    "\n",
    "지식 그래프의 힘을 활용하여 정보를 저장하고 불러옵니다.\n",
    "\n",
    "이를 통해 모델이 서로 다른 개체 간의 관계를 이해하는 데 도움을 주고, 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
    "\n",
    "# 1번째 대화\n",
    "memory.save_context(\n",
    "    {\"input\": \"이분은 서울 강남에 거주하는 이민호씨입니다.\"},\n",
    "    {\"output\": \"아, 이민호씨는 어디에서 일하시나요?\"},\n",
    ")\n",
    "\n",
    "# 2번째 대화\n",
    "memory.save_context(\n",
    "    {\"input\": \"이민호씨는 네이버의 백엔드 개발자입니다.\"},\n",
    "    {\"output\": \"네이버에서 근무하시는군요. 반갑습니다.\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On 이민호씨: 이민호씨 거주하는 서울 강남에. 이민호씨 is a 백엔드 개발자. 이민호씨 works at 네이버.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"이민호씨는 누구입니까?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 에 메모리 활용하기\n",
    "\n",
    "`ConversationChain` 에 `ConversationKGMemory` 를 메모리로 지정하여 대화를 나눈 후 memory 를 확인해 보도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\손용훈\\AppData\\Local\\Temp\\ipykernel_13600\\3821018149.py:23: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation_with_kg = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"다음은 인간과 도라에몽 사이의 즐거운 대화입니다. \n",
    "도라에몽은 친근하고 상상력이 풍부하며, 비밀도구를 활용해 유쾌한 답변을 해줍니다. \n",
    "만약 도라에몽이 어떤 질문에 대해 모른다면 솔직하게 모른다고 말합니다. \n",
    "도라에몽은 반드시 아래 \"관련 정보\"에 포함된 내용만 사용하며, 지어내지 않습니다.\n",
    "\n",
    "관련 정보:\n",
    "\n",
    "{history}\n",
    "\n",
    "대화:\n",
    "사람: {input}\n",
    "도라에몽:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 대화를 시작합니다. 간단한 인물에 대한 정보를 제공해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕 손용훈! 반가워. 노진구 친구라니, 그럼 우리도 친구가 되어야겠네. 어떤 도움이 필요하면 언제든지 말해줘!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(\n",
    "    input=\"안녕 도라에몽! 나는 손용훈이라고 해. 내 친구 노진구는 우리 학교에 전학온 친구야. 잘 부탁해!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shirley 라는 사람에 대한 질문을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On 노진구: 노진구 전학온 우리 학교에.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노진구 에 대한 질문\n",
    "conversation_with_kg.memory.load_memory_variables({\"input\": \"노진구는 누구야?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-20250820-llm-ollama-serpapi-outputpa-R4rR796i-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
