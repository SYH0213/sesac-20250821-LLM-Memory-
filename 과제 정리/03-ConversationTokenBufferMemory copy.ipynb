{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationTokenBufferMemory\n",
    "\n",
    "`ConversationTokenBufferMemory` 는 최근 대화의 히스토리를 버퍼를 메모리에 보관하고, 대화의 개수가 아닌 **토큰 길이** 를 사용하여 대화내용을 플러시(flush)할 시기를 결정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_token_limit`: 대화 내용을 저장할 최대 토큰의 길이를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\")\n",
    "\n",
    "# 메모리 설정\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm, max_token_limit=300, return_messages=True  # 최대 토큰 길이를 50개로 제한\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 대화를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕? 내 이름은 손용훈이야.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요, 손용훈님! 만나서 반가워요. 저는 여러분과 대화하고 도움을 드리기 위해 여기 있는 AI입니다. 오늘은 어떤 이야기를 나누고 싶으신가요? 혹시 관심 있는 주제나 궁금한 점이 있나요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"오늘의 날씨는 맑아.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"오늘 날씨가 맑다니 정말 기분 좋은 소식이네요! 맑은 날씨에는 야외 활동하기도 좋고, 햇볕을 쬐면서 기분 전환하기에도 딱이죠. 손용훈님은 맑은 날씨에 주로 어떤 활동을 즐기시나요? 혹시 산책이나 운동, 아니면 사진 찍기 같은 취미가 있으신가요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"오늘은 메모리에 대해 배웠어.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"메모리에 대해 배우셨다니 정말 흥미로운 주제네요! 컴퓨터에서 말하는 메모리는 데이터를 저장하고 처리하는 데 중요한 역할을 하는 장치인데요, 크게 두 가지로 나눌 수 있어요. 하나는 RAM(랜덤 액세스 메모리)으로, 컴퓨터가 작업을 수행할 때 임시로 데이터를 저장하는 곳이고, 다른 하나는 저장 장치(예: 하드 드라이브나 SSD)로, 장기적으로 데이터를 보관하는 역할을 하죠. 사람의 뇌에서 말하는 메모리도 비슷하게 정보를 저장하고 기억하는 기능을 하는데, 단기 기억과 장기 기억으로 나뉘고, 학습과 경험을 통해 강화되기도 해요. 손용훈님은 메모리 중에서 어떤 부분에 대해 배우셨나요? 컴퓨터 메모리인지, 아니면 인간의 기억에 관한 내용인지 궁금하네요!\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"내 이름이 뭔지 아니?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 손용훈님이라고 하셨어요! 기억해두었으니 앞으로도 편하게 이름을 불러드릴게요. 혹시 이름과 관련된 특별한 이야기나 의미가 있으신가요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"안녕\"},\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요, 손용훈님! 다시 만나서 반가워요. 오늘은 어떤 이야기를 나누고 싶으신가요? 궁금한 점이나 배우고 싶은 주제가 있으면 언제든 말씀해 주세요!\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"오늘의 날씨는?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"손용훈님, 오늘의 날씨에 대해 알려드리고 싶지만, 저는 실시간 정보에 접근할 수 없어서 현재 날씨를 직접 확인해 드리기는 어려워요. 대신, 날씨를 확인하려면 스마트폰의 날씨 앱이나 인터넷 포털 사이트, 또는 기상청 웹사이트를 이용하시면 가장 정확한 정보를 얻으실 수 있습니다. 오늘 외출 계획이 있으시다면, 날씨 확인 꼭 잊지 마세요! 혹시 다른 궁금한 점이나 도움이 필요한 주제가 있으면 언제든 말씀해 주세요.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최대 토큰의 길이를 **300** 으로 설정하고 대화를 저장했을 때 어떻게 동작하는지 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='내 이름이 뭔지 아니?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='네, 손용훈님이라고 하셨어요! 기억해두었으니 앞으로도 편하게 이름을 불러드릴게요. 혹시 이름과 관련된 특별한 이야기나 의미가 있으신가요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 손용훈님! 다시 만나서 반가워요. 오늘은 어떤 이야기를 나누고 싶으신가요? 궁금한 점이나 배우고 싶은 주제가 있으면 언제든 말씀해 주세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='오늘의 날씨는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='손용훈님, 오늘의 날씨에 대해 알려드리고 싶지만, 저는 실시간 정보에 접근할 수 없어서 현재 날씨를 직접 확인해 드리기는 어려워요. 대신, 날씨를 확인하려면 스마트폰의 날씨 앱이나 인터넷 포털 사이트, 또는 기상청 웹사이트를 이용하시면 가장 정확한 정보를 얻으실 수 있습니다. 오늘 외출 계획이 있으시다면, 날씨 확인 꼭 잊지 마세요! 혹시 다른 궁금한 점이나 도움이 필요한 주제가 있으면 언제든 말씀해 주세요.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대화내용을 확인합니다.\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-20250820-llm-ollama-serpapi-outputpa-R4rR796i-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
